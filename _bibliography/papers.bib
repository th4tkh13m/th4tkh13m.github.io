@article{nguyen2026noir,
  title={NOIR: Privacy-Preserving Generation of Code with Open-Source LLMs},
  author={Nguyen, Khoa and Ton, Khiem and Phan, NhatHai and Khalil, Issa and Tran, Khang and Borcea, Cristian and Jin, Ruoming and Khreishah, Abdallah and Thai, My T},
  journal={arXiv preprint arXiv:2601.16354},
  year={2026},
  selected={true},
  abstract={Although boosting software development performance, large language model (LLM)-powered code generation introduces intellectual property and data security risks rooted in the fact that a service provider (cloud) observes a client's prompts and generated code, which can be proprietary in commercial systems. To mitigate this problem, we propose NOIR, the first framework to protect the client's prompts and generated code from the cloud. NOIR uses an encoder and a decoder at the client to encode and send the prompts' embeddings to the cloud to get enriched embeddings from the LLM, which are then decoded to generate the code locally at the client. Since the cloud can use the embeddings to infer the prompt and the generated code, NOIR introduces a new mechanism to achieve indistinguishability, a local differential privacy protection at the token embedding level, in the vocabulary used in the prompts and code, and a data-independent and randomized tokenizer on the client side. These components effectively defend against reconstruction and frequency analysis attacks by an honest-but-curious cloud. Extensive analysis and results using open-source LLMs show that NOIR significantly outperforms existing baselines on benchmarks, including the Evalplus (MBPP and HumanEval, Pass@1 of 76.7 and 77.4), and BigCodeBench (Pass@1 of 38.7, only a 1.77% drop from the original LLM) under strong privacy against attacks.}
}

@inproceedings{ton2024sgcode,
  title={Sgcode: A flexible prompt-optimizing system for secure generation of code},
  author={Ton, Khiem and Nguyen, Nhi and Nazzal, Mahmoud and Khreishah, Abdallah and Borcea, Cristian and Phan, NhatHai and Jin, Ruoming and Khalil, Issa and Shen, Yelong},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={5078--5080},
  year={2024},
  abstract={This paper introduces SGCode, a flexible prompt-optimizing system to generate secure code with large language models (LLMs).SGCode integrates recent prompt-optimization approaches with
LLMs in a unified system accessible through front-end and backend APIs, enabling users to 1) generate secure code, which is free of
vulnerabilities, 2) review and share security analysis, and 3) easily
switch from one prompt optimization approach to another, while
providing insights on model and system performance. We populated SGCode on an AWS server with PromSec, an approach that
optimizes prompts by combining an LLM and security tools with a
lightweight generative adversarial graph neural network to detect
and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain
insights into the trade-offs between model utility, secure code generation, and system cost. SGCode has only a marginal cost compared
with prompting LLMs.}
}